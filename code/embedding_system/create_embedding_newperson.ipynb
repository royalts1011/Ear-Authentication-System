{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('ear')",
   "metadata": {
    "interpreter": {
     "hash": "c2e483ab6d2869a436ac078172a85a5d29909efb0d20a1467c5a44ad2f46e474"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from os.path import join, exists\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# own scripts\n",
    "import training.ds_transformations as td\n",
    "import training.helpers as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    DEVICE = hp.get_device()\n",
    "    DATASET_DIR = '../dataset/'\n",
    "    MODEL_DIR = './models/ve_g_margin_2,0.pt'\n",
    "    is_small_resize = False\n",
    "    DATABASE_FOLDER = './embeddings/radius_2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_person = hp.choose_folder(dataset_path=Config.DATASET_DIR)\n",
    "check = exists(join(Config.DATABASE_FOLDER, new_person+'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if check: print('The embedding of that person might already exist. Please check the folder first!')\n",
    "\n",
    "print('You chose ', new_person, ' to be processed.', '\\n ABORT NOW, OR:')\n",
    "input('Press any key to continue.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(Config.MODEL_DIR, map_location=torch.device(Config.DEVICE))\n",
    "transformation = td.get_transform('siamese_valid_and_test', Config.is_small_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(input_, preprocess):\n",
    "    input_ = input_.convert(\"L\")\n",
    "    input_ = preprocess(input_)\n",
    "    input_ = input_.reshape(-1, td.get_resize(Config.is_small_resize)[0], td.get_resize(Config.is_small_resize)[1], 1)\n",
    "    input_ = input_.permute(3, 0, 1, 2)   \n",
    "    if cuda.is_available():\n",
    "        return input_.type('torch.cuda.FloatTensor')\n",
    "    else:\n",
    "        return input_.type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "image_list = []\n",
    "for filename in glob.glob( join(Config.DATASET_DIR, new_person, '*') ):\n",
    "    img = Image.open(filename)\n",
    "    img_processed = pipeline(img,transformation)\n",
    "    image_list.append(img_processed)\n",
    "    \n",
    "embeddings = np.array([model(Variable(i)).cpu() for i in image_list])\n",
    "    \n",
    "np.save( join(Config.DATABASE_FOLDER,new_person+'.npy'), embeddings)    "
   ]
  }
 ]
}